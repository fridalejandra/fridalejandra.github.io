---
layout: single
title: "Simulating the Annual Cycle of Antarctic Sea Ice"
date: 2025-04-03
tags: [ml]
author_profile: true
excerpt: "Forecasting Antarctic sea ice extent using climate drivers and machine learning."
---

This work explores machine learning models to predict Antarctic sea ice extent, with a focus on forecasting its minimum extents.  
üëâ [Access the data and code here](#).

***

## Introduction

Sea ice plays a pivotal role in the Earth's climate system. It reflects most incoming solar radiation, maintains the equator-to-pole temperature gradient, and regulates heat exchange between the ocean and atmosphere. It also buffers coastal glaciers from ocean-driven melt and influences global ocean circulation.

Recent years have seen record-breaking lows in Antarctic sea ice extent, prompting the urgent need for better predictive models. Traditional physics-based approaches (like CMIP6) struggle to simulate accurate sea ice seasonality and are computationally expensive, with high inter-model variability. Machine learning (ML), on the other hand, can leverage high-frequency data to identify trends and patterns in nonlinear systems more efficiently.

This project uses supervised regression models to predict Antarctic sea ice extent based on:

- Sea surface temperature (SST)
- Surface pressure
- Air temperature
- Latent and sensible heat flux
- Time-related variables (day of year, month, etc.)

These variables were chosen for their known influence on sea ice dynamics, including thermodynamic and dynamic processes driven by climate modes such as the Southern Annular Mode and Zonal Wave 3.

### Guiding questions:
- What features are most influential in predicting sea ice?
- What model best captures Antarctic sea ice variability?
- What is the predictive accuracy of ML models?

---

## Data

We use daily sea ice extent (SIE) from 1979 to 2023 obtained from the [NSIDC](https://nsidc.org/), and daily ERA5 reanalysis data from ECMWF for the same period. Datasets were spatially averaged over the Southern Ocean region (50¬∞S‚Äì90¬∞S) and aligned in time for compatibility.

| **Variable**                | **Description**                                      | **Units**     | **Source**       |
|-----------------------------|------------------------------------------------------|---------------|------------------|
| Sea Ice Extent (SIE)        | Total area with >15% sea ice concentration           | 10‚Å∂ km¬≤       | NSIDC            |
| Sea Surface Temperature     | Ocean temperature at surface                         | ¬∞C            | ERA5             |
| Surface Pressure            | Atmospheric pressure at surface                      | hPa           | ERA5             |
| Air Surface Temperature     | 2-meter air temperature                              | ¬∞C            | ERA5             |
| Latent & Sensible Heat Flux | Ocean-atmosphere energy exchanges                    | W/m¬≤          | ERA5             |

Time features included:
- `Day_of_Year`
- `Month`
- `sin_day` and `cos_day` for cyclical encoding

All variables were preprocessed, interpolated (when needed), and missing values handled before modeling.

![](/assets/IMG/datapenguin.png){: .align-center width="500px" }

**Figure 1.** Diagram of input variables used to predict Antarctic sea ice extent [1].

---

## Modeling Approach

### Feature Engineering

Lagged features were introduced to capture memory effects of sea ice, especially on longer seasonal cycles. The following lag durations were tested for SIE:

| **Lag Period** | **Duration** |
|----------------|--------------|
| 1-month        | 30 days      |
| 6-month        | 180 days     |
| 12-month       | 365 days     |

Lagged inputs help models recognize temporal dependencies, especially when the ocean‚Äôs response to atmospheric forcing is delayed.

### Models Tested
- **Random Forest Regressor**
- **Gradient Boosting Regressor**
- **Linear Regression (Baseline)**

Hyperparameters were tuned using grid search and time-based cross-validation.

Example code snippet:
```python
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.model_selection import TimeSeriesSplit, GridSearchCV

model = GradientBoostingRegressor()
params = {'n_estimators': [100, 200], 'learning_rate': [0.05, 0.1]}
search = GridSearchCV(model, params, cv=TimeSeriesSplit(n_splits=5))
search.fit(X_train, y_train)
